{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "edb9596f1ed1432a9ed2a341e1c9bd8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f743bb98fdee4bb9ae75e34947ac0e7b",
              "IPY_MODEL_c50f28d8d4d2422abc7a33f5931229c6",
              "IPY_MODEL_526c939190624931bf146c09528d99be"
            ],
            "layout": "IPY_MODEL_fc67d01d2cc34204896c10226f901c74"
          }
        },
        "f743bb98fdee4bb9ae75e34947ac0e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f9c35eed36f47ab9ce1c7f88a35b5b3",
            "placeholder": "​",
            "style": "IPY_MODEL_ff71cd47a608401bb40f14184c33d735",
            "value": "modules.json: 100%"
          }
        },
        "c50f28d8d4d2422abc7a33f5931229c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9291a09eb60348c898f735e90e4a212d",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_721da1d2db514697aef7b2197462211d",
            "value": 349
          }
        },
        "526c939190624931bf146c09528d99be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d43be825def4e19a91fa7aa4dd89df9",
            "placeholder": "​",
            "style": "IPY_MODEL_d58bd2c71059431d8985e2e2a02fe38e",
            "value": " 349/349 [00:00&lt;00:00, 24.5kB/s]"
          }
        },
        "fc67d01d2cc34204896c10226f901c74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f9c35eed36f47ab9ce1c7f88a35b5b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff71cd47a608401bb40f14184c33d735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9291a09eb60348c898f735e90e4a212d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "721da1d2db514697aef7b2197462211d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d43be825def4e19a91fa7aa4dd89df9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d58bd2c71059431d8985e2e2a02fe38e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b3f81c7966e43a381a1f4d57ac32c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a30d49dce7640348a9c24603c1d2592",
              "IPY_MODEL_d3877e511bba4126bd0d583613f2124e",
              "IPY_MODEL_23dce8f629db4335b9ad5c6e4d933c4e"
            ],
            "layout": "IPY_MODEL_ca4ed36f65414ddfbe235aa167654191"
          }
        },
        "6a30d49dce7640348a9c24603c1d2592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3cd4a00f04041bea074ff43afeb179b",
            "placeholder": "​",
            "style": "IPY_MODEL_19341f70436247848c45ac748b4f8749",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "d3877e511bba4126bd0d583613f2124e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c5df1e351bc40c9a716191f7c22a042",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ad6b77602b6400cad4cc99e59505245",
            "value": 116
          }
        },
        "23dce8f629db4335b9ad5c6e4d933c4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e83cdf07d6e4340bb5010f0b4c90a1d",
            "placeholder": "​",
            "style": "IPY_MODEL_54d0f187f39747b3b16afa2866fbcd81",
            "value": " 116/116 [00:00&lt;00:00, 8.68kB/s]"
          }
        },
        "ca4ed36f65414ddfbe235aa167654191": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3cd4a00f04041bea074ff43afeb179b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19341f70436247848c45ac748b4f8749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c5df1e351bc40c9a716191f7c22a042": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ad6b77602b6400cad4cc99e59505245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e83cdf07d6e4340bb5010f0b4c90a1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54d0f187f39747b3b16afa2866fbcd81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a533e660e2814c69b83cc2015ecb0a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a12d69fd6a54705b409fffb1701a201",
              "IPY_MODEL_5e383753997e49ad9ca437ab9439211b",
              "IPY_MODEL_8a9b9decdb104907891a7ee63464f585"
            ],
            "layout": "IPY_MODEL_1d42a364f881410da689e72540902701"
          }
        },
        "5a12d69fd6a54705b409fffb1701a201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa28da1815824f1196466db81e845e4d",
            "placeholder": "​",
            "style": "IPY_MODEL_a356030da8034e2b83a46a39ce63bd75",
            "value": "README.md: 100%"
          }
        },
        "5e383753997e49ad9ca437ab9439211b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eed908e3ad264cc3a64de77ec72813a9",
            "max": 10659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8894a6852a247749a56e6ac72c78302",
            "value": 10659
          }
        },
        "8a9b9decdb104907891a7ee63464f585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f8b76a6def24fe79e0da5b861a91afb",
            "placeholder": "​",
            "style": "IPY_MODEL_2e802d28298841eeaf2a15efc8869730",
            "value": " 10.7k/10.7k [00:00&lt;00:00, 841kB/s]"
          }
        },
        "1d42a364f881410da689e72540902701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa28da1815824f1196466db81e845e4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a356030da8034e2b83a46a39ce63bd75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eed908e3ad264cc3a64de77ec72813a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8894a6852a247749a56e6ac72c78302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f8b76a6def24fe79e0da5b861a91afb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e802d28298841eeaf2a15efc8869730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e74b155d2554760986320fb26a95c93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4eec4ced4a1b4d7197dc661ec3addeda",
              "IPY_MODEL_ead8090a63e74047890e7ae8949f1316",
              "IPY_MODEL_1d4ec3911d7b4034bf5ade43595a77c0"
            ],
            "layout": "IPY_MODEL_4e08f31700dd43e0815fc749ce49bfb3"
          }
        },
        "4eec4ced4a1b4d7197dc661ec3addeda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dc9b3e86130459fae5070859a66a355",
            "placeholder": "​",
            "style": "IPY_MODEL_6d09407291954069ae95d3342954354c",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "ead8090a63e74047890e7ae8949f1316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a01a528f37c4683bd7cd520f3def3c9",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f8dc678f457c42cd88f8e11bdc5ccb0b",
            "value": 53
          }
        },
        "1d4ec3911d7b4034bf5ade43595a77c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6bcad97777946ee8fa637410e733c0f",
            "placeholder": "​",
            "style": "IPY_MODEL_5f4796017ca6484fa1adfc66b4821a08",
            "value": " 53.0/53.0 [00:00&lt;00:00, 4.31kB/s]"
          }
        },
        "4e08f31700dd43e0815fc749ce49bfb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dc9b3e86130459fae5070859a66a355": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d09407291954069ae95d3342954354c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a01a528f37c4683bd7cd520f3def3c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8dc678f457c42cd88f8e11bdc5ccb0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6bcad97777946ee8fa637410e733c0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f4796017ca6484fa1adfc66b4821a08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f97209d5f80144a7b5b4ec85447d5f14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c2237652a8d4644b3473a53d8badc49",
              "IPY_MODEL_c154ad60c9bf4545b8aa44095fbb48ad",
              "IPY_MODEL_b8ddf8fa0a254462b9d9f2e1301438f3"
            ],
            "layout": "IPY_MODEL_39b3c8299e9048ff8313e17a692bf51e"
          }
        },
        "4c2237652a8d4644b3473a53d8badc49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26117e119bf149ff8414b8a3ca13df2f",
            "placeholder": "​",
            "style": "IPY_MODEL_d98c406360244e4b8904c23ba8cdec43",
            "value": "config.json: 100%"
          }
        },
        "c154ad60c9bf4545b8aa44095fbb48ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f42fab9da634b698ef583f7a4e85d73",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fcf8938bb26f4ba79f82c5b9380a3d39",
            "value": 612
          }
        },
        "b8ddf8fa0a254462b9d9f2e1301438f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5f65f69ae9b42479d3a9a462ef34eb7",
            "placeholder": "​",
            "style": "IPY_MODEL_4b3d852cf7be4807adcbf277e9efda87",
            "value": " 612/612 [00:00&lt;00:00, 44.5kB/s]"
          }
        },
        "39b3c8299e9048ff8313e17a692bf51e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26117e119bf149ff8414b8a3ca13df2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d98c406360244e4b8904c23ba8cdec43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f42fab9da634b698ef583f7a4e85d73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcf8938bb26f4ba79f82c5b9380a3d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5f65f69ae9b42479d3a9a462ef34eb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b3d852cf7be4807adcbf277e9efda87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c963e4c3483b445a98f408b77202ad0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62bb7e2ff0e34cdb914ebe961dea5c92",
              "IPY_MODEL_1457817214bc4c5f85ba0ec22d8d874e",
              "IPY_MODEL_ca0527f69706481fb7714edfd23b1655"
            ],
            "layout": "IPY_MODEL_08175bd3a61340a8810809ac7ba13916"
          }
        },
        "62bb7e2ff0e34cdb914ebe961dea5c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbc46582b4e94261b6dbda202444c18a",
            "placeholder": "​",
            "style": "IPY_MODEL_cd55e035351e4fd5893c6511e7ff1eca",
            "value": "model.safetensors: 100%"
          }
        },
        "1457817214bc4c5f85ba0ec22d8d874e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f7e1b7f5a4c4bca9187f678edb42635",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4697601ed7f4a74a18cbf9731d58285",
            "value": 90868376
          }
        },
        "ca0527f69706481fb7714edfd23b1655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f416b04087734566a496e9add86569fc",
            "placeholder": "​",
            "style": "IPY_MODEL_c34260d0701d43969f2a119b5d98a806",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 271MB/s]"
          }
        },
        "08175bd3a61340a8810809ac7ba13916": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbc46582b4e94261b6dbda202444c18a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd55e035351e4fd5893c6511e7ff1eca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f7e1b7f5a4c4bca9187f678edb42635": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4697601ed7f4a74a18cbf9731d58285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f416b04087734566a496e9add86569fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c34260d0701d43969f2a119b5d98a806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "774cc0f8ba674df291ae7fefbde64f7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4f1f1e70936419e8efb74bca2c67a06",
              "IPY_MODEL_c30397bd69b341e8910cf8abc547fddd",
              "IPY_MODEL_8692e9867d2e459d989df21aa29dc983"
            ],
            "layout": "IPY_MODEL_6d45cdd6774f4cda85aaacfe00fa18c7"
          }
        },
        "b4f1f1e70936419e8efb74bca2c67a06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df31321479d8452aa69b7aa94ea586cf",
            "placeholder": "​",
            "style": "IPY_MODEL_4833432ff3e541a79fa6b994dc4c9184",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "c30397bd69b341e8910cf8abc547fddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27083d92af0d41aaa65d80f12cd9fc46",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a038460605ab4da09da783c00a050bd8",
            "value": 350
          }
        },
        "8692e9867d2e459d989df21aa29dc983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc1ca55ea3224784ac7138091c1dee83",
            "placeholder": "​",
            "style": "IPY_MODEL_448c11c199094185947b6530fe27cd7b",
            "value": " 350/350 [00:00&lt;00:00, 25.8kB/s]"
          }
        },
        "6d45cdd6774f4cda85aaacfe00fa18c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df31321479d8452aa69b7aa94ea586cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4833432ff3e541a79fa6b994dc4c9184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27083d92af0d41aaa65d80f12cd9fc46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a038460605ab4da09da783c00a050bd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc1ca55ea3224784ac7138091c1dee83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "448c11c199094185947b6530fe27cd7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c54ea0c4b20d44bc8ab5459d9d65ffd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4747b8d6ef7641398b91ea0ce11817ef",
              "IPY_MODEL_1437f0be35b047ea859f79058fd945cd",
              "IPY_MODEL_e4f1654ac9da4aa1bf9d8e773440696c"
            ],
            "layout": "IPY_MODEL_c7d9f43a6e3a4b5ebead4f3403350937"
          }
        },
        "4747b8d6ef7641398b91ea0ce11817ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfbba69df82f4e1498684549b88d3b1d",
            "placeholder": "​",
            "style": "IPY_MODEL_e4f28c2a368a405eb6b32c46ad7e4833",
            "value": "vocab.txt: 100%"
          }
        },
        "1437f0be35b047ea859f79058fd945cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d687c6e13b24b828723b52c83b535ea",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf75fb0adb1644eda4c9a6bb23958b2c",
            "value": 231508
          }
        },
        "e4f1654ac9da4aa1bf9d8e773440696c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4749931e09734aee8e37e34e5091fe72",
            "placeholder": "​",
            "style": "IPY_MODEL_e86e92fa86ae408ba1084064ae4995f4",
            "value": " 232k/232k [00:00&lt;00:00, 8.38MB/s]"
          }
        },
        "c7d9f43a6e3a4b5ebead4f3403350937": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfbba69df82f4e1498684549b88d3b1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4f28c2a368a405eb6b32c46ad7e4833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d687c6e13b24b828723b52c83b535ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf75fb0adb1644eda4c9a6bb23958b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4749931e09734aee8e37e34e5091fe72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e86e92fa86ae408ba1084064ae4995f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d19fdf850a144c3cadd1e7ba0ccedea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56e2432f7e914a52bc4c92f447d651e6",
              "IPY_MODEL_8bb4f2e7b3844b9bb45a24aaa6386e42",
              "IPY_MODEL_667eeb3fd45f43c38370d9f0d55ea527"
            ],
            "layout": "IPY_MODEL_adfda8b8a8b24ea2a709d3022668e8a8"
          }
        },
        "56e2432f7e914a52bc4c92f447d651e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d54ca44940e24b1a8a09b52025f5365f",
            "placeholder": "​",
            "style": "IPY_MODEL_0666058432ce46fc96c56b7a63f16c78",
            "value": "tokenizer.json: 100%"
          }
        },
        "8bb4f2e7b3844b9bb45a24aaa6386e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_207f4a45c3f745d892dcb13e8df794f8",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7a1ed24ff4944c39949f674b5663e77",
            "value": 466247
          }
        },
        "667eeb3fd45f43c38370d9f0d55ea527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a46335da4c24a2aacf7fa05fb01daa5",
            "placeholder": "​",
            "style": "IPY_MODEL_5c22401e20ee477596b526680c9b4c3c",
            "value": " 466k/466k [00:00&lt;00:00, 26.6MB/s]"
          }
        },
        "adfda8b8a8b24ea2a709d3022668e8a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d54ca44940e24b1a8a09b52025f5365f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0666058432ce46fc96c56b7a63f16c78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "207f4a45c3f745d892dcb13e8df794f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7a1ed24ff4944c39949f674b5663e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a46335da4c24a2aacf7fa05fb01daa5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c22401e20ee477596b526680c9b4c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b489ca18d34b4a2b9ede155c7635ee2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f37ef76919a54af69cf60771a28c01cc",
              "IPY_MODEL_c2a8d8c7e2f24bf89d73178d3a2472b9",
              "IPY_MODEL_0a9b22d1bb744fb2980e0dabe5559aa5"
            ],
            "layout": "IPY_MODEL_8478b2a11ca9486d825f69319534e937"
          }
        },
        "f37ef76919a54af69cf60771a28c01cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f37ea82ed894c4bbe442c68efd98f3f",
            "placeholder": "​",
            "style": "IPY_MODEL_685756d9412640c4b600391f625db0c6",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "c2a8d8c7e2f24bf89d73178d3a2472b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a839e0693c4e431eaa8c5d15ef96f4b4",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2292c92a533444baad864f8fe1e036c4",
            "value": 112
          }
        },
        "0a9b22d1bb744fb2980e0dabe5559aa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e12799ae359470aa1c7c4a0a5ef71ee",
            "placeholder": "​",
            "style": "IPY_MODEL_7e36a2d818434d13a3643889f198d83d",
            "value": " 112/112 [00:00&lt;00:00, 6.17kB/s]"
          }
        },
        "8478b2a11ca9486d825f69319534e937": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f37ea82ed894c4bbe442c68efd98f3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "685756d9412640c4b600391f625db0c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a839e0693c4e431eaa8c5d15ef96f4b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2292c92a533444baad864f8fe1e036c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e12799ae359470aa1c7c4a0a5ef71ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e36a2d818434d13a3643889f198d83d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "902f93d1fbe2454e9c29da4cfd581dc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_502571b61116489683d8c17eddf488f3",
              "IPY_MODEL_1c336fdac12941be8cddd5c46b95c20b",
              "IPY_MODEL_a82a890d5a9e42e4ba059ca5b4c90be4"
            ],
            "layout": "IPY_MODEL_4248545ee4a24fdabb78536932232329"
          }
        },
        "502571b61116489683d8c17eddf488f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbb7f0b4cd1c491494a94c5a93f24a0a",
            "placeholder": "​",
            "style": "IPY_MODEL_60efc20b3fd74153bb5af55998011405",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "1c336fdac12941be8cddd5c46b95c20b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_662cc4a21099422989a2f9447cc8e1f2",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1335363234904bf5b0bb2e2c3965510e",
            "value": 190
          }
        },
        "a82a890d5a9e42e4ba059ca5b4c90be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_153784bcca944fada4efb82a7b9d7f53",
            "placeholder": "​",
            "style": "IPY_MODEL_e8fe0c08f91c41689c74ca1908619f8d",
            "value": " 190/190 [00:00&lt;00:00, 12.1kB/s]"
          }
        },
        "4248545ee4a24fdabb78536932232329": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbb7f0b4cd1c491494a94c5a93f24a0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60efc20b3fd74153bb5af55998011405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "662cc4a21099422989a2f9447cc8e1f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1335363234904bf5b0bb2e2c3965510e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "153784bcca944fada4efb82a7b9d7f53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8fe0c08f91c41689c74ca1908619f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community sentence-transformers ctransformers pypdf faiss-gpu huggingface_hub matplotlib llama-cpp-python langchain\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrZ2EI9HTdqR",
        "outputId": "95fd0895-b2f4-4aa7-c065-ca202e6e3124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.17-py3-none-any.whl (867 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.6/867.6 kB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.5-py3-none-any.whl (28 kB)\n",
            "Collecting langchain-core<0.2.0,>=0.1.48 (from langchain_community)\n",
            "  Downloading langchain_core-0.1.50-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.2.0,>=0.1.0 (from langchain_community)\n",
            "  Downloading langsmith-0.1.54-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.7/116.7 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.2.3)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.40.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from ctransformers) (9.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging>=20.9 (from huggingface_hub)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain_community)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.69-cp310-cp310-linux_x86_64.whl size=3585974 sha256=cf8515a540fdb25ee823fc02cbe59748498ff9365c9f4a0cf00ef4b443f47981\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/18/46/58b5c613b17c8d000d79ae650980fe871b3b490e04e6faa1c1\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: faiss-gpu, pypdf, packaging, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, jsonpointer, diskcache, typing-inspect, nvidia-cusparse-cu12, nvidia-cudnn-cu12, marshmallow, llama-cpp-python, jsonpatch, nvidia-cusolver-cu12, langsmith, dataclasses-json, ctransformers, langchain-core, sentence-transformers, langchain-text-splitters, langchain_community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed ctransformers-0.2.27 dataclasses-json-0.6.5 diskcache-5.6.3 faiss-gpu-1.7.2 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.17 langchain-core-0.1.50 langchain-text-splitters-0.0.1 langchain_community-0.0.36 langsmith-0.1.54 llama-cpp-python-0.2.69 marshmallow-3.21.2 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 orjson-3.10.3 packaging-23.2 pypdf-4.2.0 sentence-transformers-2.7.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493,
          "referenced_widgets": [
            "edb9596f1ed1432a9ed2a341e1c9bd8f",
            "f743bb98fdee4bb9ae75e34947ac0e7b",
            "c50f28d8d4d2422abc7a33f5931229c6",
            "526c939190624931bf146c09528d99be",
            "fc67d01d2cc34204896c10226f901c74",
            "7f9c35eed36f47ab9ce1c7f88a35b5b3",
            "ff71cd47a608401bb40f14184c33d735",
            "9291a09eb60348c898f735e90e4a212d",
            "721da1d2db514697aef7b2197462211d",
            "1d43be825def4e19a91fa7aa4dd89df9",
            "d58bd2c71059431d8985e2e2a02fe38e",
            "0b3f81c7966e43a381a1f4d57ac32c5d",
            "6a30d49dce7640348a9c24603c1d2592",
            "d3877e511bba4126bd0d583613f2124e",
            "23dce8f629db4335b9ad5c6e4d933c4e",
            "ca4ed36f65414ddfbe235aa167654191",
            "a3cd4a00f04041bea074ff43afeb179b",
            "19341f70436247848c45ac748b4f8749",
            "8c5df1e351bc40c9a716191f7c22a042",
            "9ad6b77602b6400cad4cc99e59505245",
            "9e83cdf07d6e4340bb5010f0b4c90a1d",
            "54d0f187f39747b3b16afa2866fbcd81",
            "a533e660e2814c69b83cc2015ecb0a6b",
            "5a12d69fd6a54705b409fffb1701a201",
            "5e383753997e49ad9ca437ab9439211b",
            "8a9b9decdb104907891a7ee63464f585",
            "1d42a364f881410da689e72540902701",
            "fa28da1815824f1196466db81e845e4d",
            "a356030da8034e2b83a46a39ce63bd75",
            "eed908e3ad264cc3a64de77ec72813a9",
            "e8894a6852a247749a56e6ac72c78302",
            "5f8b76a6def24fe79e0da5b861a91afb",
            "2e802d28298841eeaf2a15efc8869730",
            "7e74b155d2554760986320fb26a95c93",
            "4eec4ced4a1b4d7197dc661ec3addeda",
            "ead8090a63e74047890e7ae8949f1316",
            "1d4ec3911d7b4034bf5ade43595a77c0",
            "4e08f31700dd43e0815fc749ce49bfb3",
            "3dc9b3e86130459fae5070859a66a355",
            "6d09407291954069ae95d3342954354c",
            "5a01a528f37c4683bd7cd520f3def3c9",
            "f8dc678f457c42cd88f8e11bdc5ccb0b",
            "c6bcad97777946ee8fa637410e733c0f",
            "5f4796017ca6484fa1adfc66b4821a08",
            "f97209d5f80144a7b5b4ec85447d5f14",
            "4c2237652a8d4644b3473a53d8badc49",
            "c154ad60c9bf4545b8aa44095fbb48ad",
            "b8ddf8fa0a254462b9d9f2e1301438f3",
            "39b3c8299e9048ff8313e17a692bf51e",
            "26117e119bf149ff8414b8a3ca13df2f",
            "d98c406360244e4b8904c23ba8cdec43",
            "2f42fab9da634b698ef583f7a4e85d73",
            "fcf8938bb26f4ba79f82c5b9380a3d39",
            "c5f65f69ae9b42479d3a9a462ef34eb7",
            "4b3d852cf7be4807adcbf277e9efda87",
            "c963e4c3483b445a98f408b77202ad0c",
            "62bb7e2ff0e34cdb914ebe961dea5c92",
            "1457817214bc4c5f85ba0ec22d8d874e",
            "ca0527f69706481fb7714edfd23b1655",
            "08175bd3a61340a8810809ac7ba13916",
            "cbc46582b4e94261b6dbda202444c18a",
            "cd55e035351e4fd5893c6511e7ff1eca",
            "7f7e1b7f5a4c4bca9187f678edb42635",
            "c4697601ed7f4a74a18cbf9731d58285",
            "f416b04087734566a496e9add86569fc",
            "c34260d0701d43969f2a119b5d98a806",
            "774cc0f8ba674df291ae7fefbde64f7d",
            "b4f1f1e70936419e8efb74bca2c67a06",
            "c30397bd69b341e8910cf8abc547fddd",
            "8692e9867d2e459d989df21aa29dc983",
            "6d45cdd6774f4cda85aaacfe00fa18c7",
            "df31321479d8452aa69b7aa94ea586cf",
            "4833432ff3e541a79fa6b994dc4c9184",
            "27083d92af0d41aaa65d80f12cd9fc46",
            "a038460605ab4da09da783c00a050bd8",
            "fc1ca55ea3224784ac7138091c1dee83",
            "448c11c199094185947b6530fe27cd7b",
            "c54ea0c4b20d44bc8ab5459d9d65ffd4",
            "4747b8d6ef7641398b91ea0ce11817ef",
            "1437f0be35b047ea859f79058fd945cd",
            "e4f1654ac9da4aa1bf9d8e773440696c",
            "c7d9f43a6e3a4b5ebead4f3403350937",
            "bfbba69df82f4e1498684549b88d3b1d",
            "e4f28c2a368a405eb6b32c46ad7e4833",
            "0d687c6e13b24b828723b52c83b535ea",
            "cf75fb0adb1644eda4c9a6bb23958b2c",
            "4749931e09734aee8e37e34e5091fe72",
            "e86e92fa86ae408ba1084064ae4995f4",
            "d19fdf850a144c3cadd1e7ba0ccedea7",
            "56e2432f7e914a52bc4c92f447d651e6",
            "8bb4f2e7b3844b9bb45a24aaa6386e42",
            "667eeb3fd45f43c38370d9f0d55ea527",
            "adfda8b8a8b24ea2a709d3022668e8a8",
            "d54ca44940e24b1a8a09b52025f5365f",
            "0666058432ce46fc96c56b7a63f16c78",
            "207f4a45c3f745d892dcb13e8df794f8",
            "e7a1ed24ff4944c39949f674b5663e77",
            "1a46335da4c24a2aacf7fa05fb01daa5",
            "5c22401e20ee477596b526680c9b4c3c",
            "b489ca18d34b4a2b9ede155c7635ee2f",
            "f37ef76919a54af69cf60771a28c01cc",
            "c2a8d8c7e2f24bf89d73178d3a2472b9",
            "0a9b22d1bb744fb2980e0dabe5559aa5",
            "8478b2a11ca9486d825f69319534e937",
            "1f37ea82ed894c4bbe442c68efd98f3f",
            "685756d9412640c4b600391f625db0c6",
            "a839e0693c4e431eaa8c5d15ef96f4b4",
            "2292c92a533444baad864f8fe1e036c4",
            "6e12799ae359470aa1c7c4a0a5ef71ee",
            "7e36a2d818434d13a3643889f198d83d",
            "902f93d1fbe2454e9c29da4cfd581dc3",
            "502571b61116489683d8c17eddf488f3",
            "1c336fdac12941be8cddd5c46b95c20b",
            "a82a890d5a9e42e4ba059ca5b4c90be4",
            "4248545ee4a24fdabb78536932232329",
            "fbb7f0b4cd1c491494a94c5a93f24a0a",
            "60efc20b3fd74153bb5af55998011405",
            "662cc4a21099422989a2f9447cc8e1f2",
            "1335363234904bf5b0bb2e2c3965510e",
            "153784bcca944fada4efb82a7b9d7f53",
            "e8fe0c08f91c41689c74ca1908619f8d"
          ]
        },
        "id": "k2wmtlk4TRhi",
        "outputId": "adce40b3-ecb1-4555-aed7-1cb209f80399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "edb9596f1ed1432a9ed2a341e1c9bd8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b3f81c7966e43a381a1f4d57ac32c5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a533e660e2814c69b83cc2015ecb0a6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e74b155d2554760986320fb26a95c93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f97209d5f80144a7b5b4ec85447d5f14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c963e4c3483b445a98f408b77202ad0c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "774cc0f8ba674df291ae7fefbde64f7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c54ea0c4b20d44bc8ab5459d9d65ffd4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d19fdf850a144c3cadd1e7ba0ccedea7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b489ca18d34b4a2b9ede155c7635ee2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "902f93d1fbe2454e9c29da4cfd581dc3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "DATA_PATH = '/content/data'\n",
        "DB_FAISS_PATH = 'vectorstore/db_faiss'\n",
        "\n",
        "# Create vector database\n",
        "def create_vector_db():\n",
        "    loader = DirectoryLoader(DATA_PATH,\n",
        "                             glob='*.pdf',\n",
        "                             loader_cls=PyPDFLoader)\n",
        "\n",
        "    documents = loader.load()\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,\n",
        "                                                   chunk_overlap=50)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "\n",
        "    embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
        "                                       model_kwargs={'device':'cpu'})\n",
        "\n",
        "    db = FAISS.from_documents(texts, embeddings)\n",
        "    db.save_local(DB_FAISS_PATH)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    create_vector_db()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.llms import CTransformers, LlamaCpp\n",
        "from langchain.chains import RetrievalQA\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "# Define the database path for FAISS\n",
        "DB_FAISS_PATH = '/content/vectorstore/db_faiss'\n",
        "\n",
        "# Define a custom prompt template\n",
        "custom_prompt_template = \"\"\"Use the following pieces of information to answer the user's question.\n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "Context: {context}\n",
        "Question: {question}\n",
        "\n",
        "Only return the helpful answer below and nothing else.\n",
        "Helpful answer:\n",
        "\"\"\"\n",
        "\n",
        "def set_custom_prompt():\n",
        "    \"\"\" Prompt template for QA retrieval for each vectorstore \"\"\"\n",
        "    prompt = PromptTemplate(template=custom_prompt_template, input_variables=['context', 'question'])\n",
        "    return prompt\n",
        "\n",
        "def retrieval_qa_chain(llm, prompt, db):\n",
        "    qa_chain = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                       chain_type='stuff',\n",
        "                                       retriever=db.as_retriever(search_kwargs={'k': 2}),\n",
        "                                       return_source_documents=True,\n",
        "                                       chain_type_kwargs={'prompt': prompt}\n",
        "                                       )\n",
        "    return qa_chain\n",
        "\n",
        "def load_llm():\n",
        "    \"\"\" Load the locally downloaded model \"\"\"\n",
        "    llm = LlamaCpp(\n",
        "        streaming=True,\n",
        "        model_path=\"/content/drive/MyDrive/llama-2-7b-chat.Q4_K_M.gguf\",\n",
        "        model_type=\"llama\",\n",
        "        top_p=1,\n",
        "        max_new_tokens=512,\n",
        "        temperature=0.3\n",
        "    )\n",
        "    return llm\n",
        "\n",
        "def qa_bot():\n",
        "    \"\"\" Initialize and return the QA bot \"\"\"\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "                                       model_kwargs={'device': 'cpu'})\n",
        "    db = FAISS.load_local(DB_FAISS_PATH, embeddings, allow_dangerous_deserialization= True)\n",
        "    llm = load_llm()\n",
        "    qa_prompt = set_custom_prompt()\n",
        "    qa = retrieval_qa_chain(llm, qa_prompt, db)\n",
        "    return qa\n",
        "\n",
        "def final_result(query):\n",
        "    qa_result = qa_bot()\n",
        "    response = qa_result({'query': query})\n",
        "    answer = response['result']\n",
        "    return answer\n",
        "\n",
        "\n",
        "\n",
        "def exact_match_score(prediction, ground_truth):\n",
        "    return prediction.strip().lower() == ground_truth.strip().lower()\n",
        "\n",
        "def f1_score(prediction, ground_truth):\n",
        "    prediction_tokens = prediction.strip().lower().split()\n",
        "    ground_truth_tokens = ground_truth.strip().lower().split()\n",
        "    common_tokens = Counter(prediction_tokens) & Counter(ground_truth_tokens)\n",
        "    num_common = sum(common_tokens.values())\n",
        "    if num_common == 0:\n",
        "        return 0\n",
        "    precision = num_common / len(prediction_tokens)\n",
        "    recall = num_common / len(ground_truth_tokens)\n",
        "    return 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "def evaluate_model_detailed(model_func, dataset):\n",
        "    detailed_scores = []\n",
        "    for item in dataset:\n",
        "        question = item['question']\n",
        "        ground_truth_answer = item['answer']\n",
        "        predicted_answer = model_func(question)\n",
        "\n",
        "        em = exact_match_score(predicted_answer, ground_truth_answer)\n",
        "        f1 = f1_score(predicted_answer, ground_truth_answer)\n",
        "\n",
        "        detailed_scores.append({'question': question, 'EM': em, 'F1': f1})\n",
        "\n",
        "    return detailed_scores\n",
        "\n",
        "def plot_scores(detailed_scores):\n",
        "    \"\"\" Plot the detailed scores for Exact Match and F1 \"\"\"\n",
        "    em_scores = [item['EM'] for item in detailed_scores]\n",
        "    f1_scores = [item['F1'] for item in detailed_scores]\n",
        "    questions = range(len(detailed_scores))\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
        "    ax[0].bar(questions, em_scores, color='skyblue')\n",
        "    ax[0].set_title('Exact Match Score per Question')\n",
        "    ax[0].set_xlabel('Question Index')\n",
        "    ax[0].set_ylabel('Score')\n",
        "    ax[0].set_ylim(0, 1)\n",
        "\n",
        "    ax[1].bar(questions, f1_scores, color='blue')\n",
        "    ax[1].set_title('F1 Score per Question')\n",
        "    ax[1].set_xlabel('Question Index')\n",
        "    ax[1].set_ylabel('Score')\n",
        "    ax[1].set_ylim(0, 1)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pre_finetuned_model = load_llm()\n",
        "    dataset = [\n",
        "    {\"question\": \"How does Python's interpretation of non-zero numbers as \"\"true\"\" affect conditional statements? Can you provide an example where this might be confusing?\",  \"answer\": \"Python interprets any non-zero number as \"\"true\"\" for logical operations. This can be helpful in some situations, but it can also be confusing because it can lead to unexpected results if we are not careful. For example, suppose we have a program that checks if a number is positive: if x > 0: print(\"\"x is positive\"\") if x < 0: print(\"\"x is negative\"\") if x == 0: print(\"\"x is zero\"\") In this code, we have three if statements checking different conditions. However, if x is -10, then x is not greater than zero, but it is not less than zero either. Since x is a non-zero number, it is interpreted as \"\"true\"\" for logical operations. Therefore, the program will output: x is positive x is negative This output is unexpected and may be confusing for the user. To avoid this confusion, we should be careful when using logical operations with non-zero numbers and make sure our conditions are clear and unambiguous\"},\n",
        "    {\"question\":\"Explain the differences between syntax errors, logic errors, and semantic errors in Python programming and provide examples for each type\" , \"answer\": \"Syntax errors are mistakes in the use of the Python language syntax, such as missing colons, incorrect indentation, or misuse of keywords. For example, 'for i in range(5)' without a colon at the end. Logic errors occur when a program runs without crashing but produces incorrect results, such as calculating the average of numbers incorrectly due to an error in the summing logic. Semantic errors are related to the meaning of the program; the syntax and logic could be correct, but the program does not do what the programmer intended. An example could be using a variable name incorrectly, leading to unexpected program behavior.\"},\n",
        "    {\"question\": \"What is the purpose of function calls?\", \"answer\": \"A function is a named sequence of statements that performs a computation when called. When we define a function, we specify its name and sequence of statements. Later, we can call it by name with an argument or arguments. The argument or arguments are values or variables we pass into the function as input to the function. The result is called the return value or values. The purpose of function calls is to execute a predefined sequence of statements when called.\"},\n",
        "    {\"question\": \"What happens if we use commas between groups of digits while typing a large integer?\",\"answer\": \"Python interprets this as a comma-separated sequence of integers.\"},\n",
        "    {\"question\": \"What is a built-in function and how can it be used without defining it?\", \"answer\": \"A built-in function is a pre-defined function provided by Python's creators that can be used without defining it. To use a built-in function, simply call it with appropriate arguments inside parentheses and assign its return value to a variable or print it directly. For example: `result = max(values)` or `print(len(string))`. These functions do not require a function deﬁnition to be created beforehand, as their functionality is already provided by Python.\"},\n",
        "    {\"question\": \"Why does short-circuit evaluation lead to a clever technique like the guardian pattern?\", \"answer\": \"The short-circuit behavior of logical expressions allows us to use a technique called the guardian pattern. In this pattern, we use a logical expression that evaluates a condition and then another logical expression inside an \"\"and\"\" or \"\"or\"\" operator. By using this pattern, we can ensure that some operations are skipped if their conditions are False. This can save us time and improve performance by avoiding unnecessary computations. In the previous example, we used the guardian pattern to avoid a potential runtime error when evaluating a complex logical expression involving division by zero. By including a guardian expression (y != 0) in the logical \"},\n",
        "    {\"question\": \"What is the result or return value of a function?\" , \"answer\": \"The result or return value of a function is the value or expression that is computed and returned when the function is executed or called. When a function is called, it performs some computation on its arguments and returns a result. The result is assigned to a variable or displayed directly using print. The result is also sometimes called the output or output value of the function.\"},\n",
        "    {\"question\": \"What does the float() function do? How does it convert integers and strings to floating-point numbers?\", \"answer\": \"The float() function in Python converts its argument to a floating-point number. When converting integers to floating-point numbers, there is no rounding off involved; instead, the fraction part is simply chopped off. When converting strings, if the string can be parsed as a valid number (i.e., a valid combination of digits and decimal points), then float() converts it to a floating-point number; otherwise, it raises a ValueError exception.\"},\n",
        "    {\"question\": \"What are operators? What are their operands? How can we perform division in Python?\" , \"answer\": \"Operators are symbols that perform operations on operands (values or variables). Python supports various operators for arithmetic like +, -, *, /, and others. Division is performed using the / operator, resulting in a float.\"},\n",
        "    {\"question\": \"What happens when a function is called within another function?\" , \"answer\": \"When a function is called within another function, it is known as a nested function call or a function call within a function. This means that a function is called as part of another function's execution. The inner function may access any variables defined in the outer function as well as any variables defined in the global scope or other modules. The inner function has its own local scope where it can store variables distinct from those in the outer function's scope. The execution of the inner function will pause when it is called and will only continue when the calling function returns its result or when a return statement is executed within the inner function. This mechanism allows for complex and hierarchical program structures.\"},\n",
        "\n",
        "]\n",
        "    detailed_scores = evaluate_model_detailed(final_result, dataset)\n",
        "    plot_scores(detailed_scores)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mmYLe2ihm6Jq",
        "outputId": "b3de1df5-1167-4578-c06d-677ea75ffa8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! model_type is not default parameter.\n",
            "                model_type was transferred to model_kwargs.\n",
            "                Please confirm that model_type is what you intended.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! max_new_tokens is not default parameter.\n",
            "                max_new_tokens was transferred to model_kwargs.\n",
            "                Please confirm that max_new_tokens is what you intended.\n",
            "  warnings.warn(\n",
            "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /content/drive/MyDrive/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
            "llm_load_tensors:        CPU buffer size =  3891.24 MiB\n",
            "..................................................................................................\n",
            "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =     4.41 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
            "Using fallback chat format: None\n",
            "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /content/drive/MyDrive/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
            "llm_load_tensors:        CPU buffer size =  3891.24 MiB\n",
            "..................................................................................................\n",
            "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =     4.41 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
            "Using fallback chat format: None\n",
            "\n",
            "llama_print_timings:        load time =     918.05 ms\n",
            "llama_print_timings:      sample time =      86.29 ms /   135 runs   (    0.64 ms per token,  1564.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =   49590.48 ms /   364 tokens (  136.24 ms per token,     7.34 tokens per second)\n",
            "llama_print_timings:        eval time =   25558.89 ms /   134 runs   (  190.74 ms per token,     5.24 tokens per second)\n",
            "llama_print_timings:       total time =   75947.22 ms /   498 tokens\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! model_type is not default parameter.\n",
            "                model_type was transferred to model_kwargs.\n",
            "                Please confirm that model_type is what you intended.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! max_new_tokens is not default parameter.\n",
            "                max_new_tokens was transferred to model_kwargs.\n",
            "                Please confirm that max_new_tokens is what you intended.\n",
            "  warnings.warn(\n",
            "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /content/drive/MyDrive/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
            "llm_load_tensors:        CPU buffer size =  3891.24 MiB\n",
            "..................................................................................................\n",
            "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =     4.41 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
            "Using fallback chat format: None\n",
            "\n",
            "llama_print_timings:        load time =     880.12 ms\n",
            "llama_print_timings:      sample time =     110.26 ms /   177 runs   (    0.62 ms per token,  1605.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =   44995.74 ms /   335 tokens (  134.32 ms per token,     7.45 tokens per second)\n",
            "llama_print_timings:        eval time =   34630.02 ms /   176 runs   (  196.76 ms per token,     5.08 tokens per second)\n",
            "llama_print_timings:       total time =   80601.62 ms /   511 tokens\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! model_type is not default parameter.\n",
            "                model_type was transferred to model_kwargs.\n",
            "                Please confirm that model_type is what you intended.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! max_new_tokens is not default parameter.\n",
            "                max_new_tokens was transferred to model_kwargs.\n",
            "                Please confirm that max_new_tokens is what you intended.\n",
            "  warnings.warn(\n",
            "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /content/drive/MyDrive/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
            "llm_load_tensors:        CPU buffer size =  3891.24 MiB\n",
            "..................................................................................................\n",
            "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =     4.41 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
            "Using fallback chat format: None\n",
            "\n",
            "llama_print_timings:        load time =     860.94 ms\n",
            "llama_print_timings:      sample time =      28.46 ms /    47 runs   (    0.61 ms per token,  1651.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =   41718.29 ms /   304 tokens (  137.23 ms per token,     7.29 tokens per second)\n",
            "llama_print_timings:        eval time =    8806.64 ms /    46 runs   (  191.45 ms per token,     5.22 tokens per second)\n",
            "llama_print_timings:       total time =   50867.35 ms /   350 tokens\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! model_type is not default parameter.\n",
            "                model_type was transferred to model_kwargs.\n",
            "                Please confirm that model_type is what you intended.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! max_new_tokens is not default parameter.\n",
            "                max_new_tokens was transferred to model_kwargs.\n",
            "                Please confirm that max_new_tokens is what you intended.\n",
            "  warnings.warn(\n",
            "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /content/drive/MyDrive/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
            "llm_load_tensors:        CPU buffer size =  3891.24 MiB\n",
            "..................................................................................................\n",
            "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =     4.41 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
            "Using fallback chat format: None\n",
            "\n",
            "llama_print_timings:        load time =     914.86 ms\n",
            "llama_print_timings:      sample time =      16.21 ms /    27 runs   (    0.60 ms per token,  1665.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =   62429.17 ms /   469 tokens (  133.11 ms per token,     7.51 tokens per second)\n",
            "llama_print_timings:        eval time =    5354.25 ms /    26 runs   (  205.93 ms per token,     4.86 tokens per second)\n",
            "llama_print_timings:       total time =   68112.10 ms /   495 tokens\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! model_type is not default parameter.\n",
            "                model_type was transferred to model_kwargs.\n",
            "                Please confirm that model_type is what you intended.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! max_new_tokens is not default parameter.\n",
            "                max_new_tokens was transferred to model_kwargs.\n",
            "                Please confirm that max_new_tokens is what you intended.\n",
            "  warnings.warn(\n",
            "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /content/drive/MyDrive/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
            "llm_load_tensors:        CPU buffer size =  3891.24 MiB\n",
            "..................................................................................................\n",
            "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =     4.41 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
            "Using fallback chat format: None\n",
            "\n",
            "llama_print_timings:        load time =     905.61 ms\n",
            "llama_print_timings:      sample time =      54.56 ms /    90 runs   (    0.61 ms per token,  1649.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =   41481.61 ms /   303 tokens (  136.90 ms per token,     7.30 tokens per second)\n",
            "llama_print_timings:        eval time =   17269.29 ms /    89 runs   (  194.04 ms per token,     5.15 tokens per second)\n",
            "llama_print_timings:       total time =   59290.48 ms /   392 tokens\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! model_type is not default parameter.\n",
            "                model_type was transferred to model_kwargs.\n",
            "                Please confirm that model_type is what you intended.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! max_new_tokens is not default parameter.\n",
            "                max_new_tokens was transferred to model_kwargs.\n",
            "                Please confirm that max_new_tokens is what you intended.\n",
            "  warnings.warn(\n",
            "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /content/drive/MyDrive/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
            "llm_load_tensors:        CPU buffer size =  3891.24 MiB\n",
            "..................................................................................................\n",
            "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =     4.41 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
            "Using fallback chat format: None\n",
            "\n",
            "llama_print_timings:        load time =     921.55 ms\n",
            "llama_print_timings:      sample time =      69.06 ms /   109 runs   (    0.63 ms per token,  1578.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =   45591.40 ms /   342 tokens (  133.31 ms per token,     7.50 tokens per second)\n",
            "llama_print_timings:        eval time =   20784.10 ms /   108 runs   (  192.45 ms per token,     5.20 tokens per second)\n",
            "llama_print_timings:       total time =   67029.76 ms /   450 tokens\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! model_type is not default parameter.\n",
            "                model_type was transferred to model_kwargs.\n",
            "                Please confirm that model_type is what you intended.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! max_new_tokens is not default parameter.\n",
            "                max_new_tokens was transferred to model_kwargs.\n",
            "                Please confirm that max_new_tokens is what you intended.\n",
            "  warnings.warn(\n",
            "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /content/drive/MyDrive/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
            "llm_load_tensors:        CPU buffer size =  3891.24 MiB\n",
            "..................................................................................................\n",
            "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =     4.41 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
            "Using fallback chat format: None\n",
            "\n",
            "llama_print_timings:        load time =     865.24 ms\n",
            "llama_print_timings:      sample time =      13.97 ms /    24 runs   (    0.58 ms per token,  1718.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =   36557.05 ms /   252 tokens (  145.07 ms per token,     6.89 tokens per second)\n",
            "llama_print_timings:        eval time =    4513.90 ms /    23 runs   (  196.26 ms per token,     5.10 tokens per second)\n",
            "llama_print_timings:       total time =   41287.66 ms /   275 tokens\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! model_type is not default parameter.\n",
            "                model_type was transferred to model_kwargs.\n",
            "                Please confirm that model_type is what you intended.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! max_new_tokens is not default parameter.\n",
            "                max_new_tokens was transferred to model_kwargs.\n",
            "                Please confirm that max_new_tokens is what you intended.\n",
            "  warnings.warn(\n",
            "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /content/drive/MyDrive/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
            "llm_load_tensors:        CPU buffer size =  3891.24 MiB\n",
            "..................................................................................................\n",
            "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =     4.41 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
            "Using fallback chat format: None\n",
            "\n",
            "llama_print_timings:        load time =     923.28 ms\n",
            "llama_print_timings:      sample time =      31.39 ms /    51 runs   (    0.62 ms per token,  1624.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =   57939.75 ms /   411 tokens (  140.97 ms per token,     7.09 tokens per second)\n",
            "llama_print_timings:        eval time =    9785.15 ms /    50 runs   (  195.70 ms per token,     5.11 tokens per second)\n",
            "llama_print_timings:       total time =   68150.44 ms /   461 tokens\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! model_type is not default parameter.\n",
            "                model_type was transferred to model_kwargs.\n",
            "                Please confirm that model_type is what you intended.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! max_new_tokens is not default parameter.\n",
            "                max_new_tokens was transferred to model_kwargs.\n",
            "                Please confirm that max_new_tokens is what you intended.\n",
            "  warnings.warn(\n",
            "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /content/drive/MyDrive/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
            "llm_load_tensors:        CPU buffer size =  3891.24 MiB\n",
            "..................................................................................................\n",
            "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =     4.41 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
            "Using fallback chat format: None\n",
            "\n",
            "llama_print_timings:        load time =     916.00 ms\n",
            "llama_print_timings:      sample time =      48.60 ms /    77 runs   (    0.63 ms per token,  1584.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =   49906.25 ms /   350 tokens (  142.59 ms per token,     7.01 tokens per second)\n",
            "llama_print_timings:        eval time =   14460.64 ms /    76 runs   (  190.27 ms per token,     5.26 tokens per second)\n",
            "llama_print_timings:       total time =   64879.44 ms /   426 tokens\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! model_type is not default parameter.\n",
            "                model_type was transferred to model_kwargs.\n",
            "                Please confirm that model_type is what you intended.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! max_new_tokens is not default parameter.\n",
            "                max_new_tokens was transferred to model_kwargs.\n",
            "                Please confirm that max_new_tokens is what you intended.\n",
            "  warnings.warn(\n",
            "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /content/drive/MyDrive/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
            "llm_load_tensors:        CPU buffer size =  3891.24 MiB\n",
            "..................................................................................................\n",
            "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_new_context_with_model: n_ctx      = 512\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =     4.41 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
            "Using fallback chat format: None\n",
            "\n",
            "llama_print_timings:        load time =     926.84 ms\n",
            "llama_print_timings:      sample time =      33.40 ms /    57 runs   (    0.59 ms per token,  1706.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =   43802.99 ms /   324 tokens (  135.19 ms per token,     7.40 tokens per second)\n",
            "llama_print_timings:        eval time =   10794.94 ms /    56 runs   (  192.77 ms per token,     5.19 tokens per second)\n",
            "llama_print_timings:       total time =   55000.89 ms /   380 tokens\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}